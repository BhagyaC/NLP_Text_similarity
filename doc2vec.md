# Doc2vec and machine learning
- Problem statement : Find the relation between the news articles towards the tone of the document 
- scrap the comments from the news sites
- Preprocess the data with NLTK
- Doc2vec / word2vec
- Word2vec is the basics of doc2vec
- The word2vec give some amazing properties like if we have a word embedding for king , man , women then king - man + women will give the embedding for queen
- The word2vec can be visualize as a neural network then there is a input layer , hidden layer and a output layer
- What is doc2vec   
- It has almost a same architecture as the word2 vec where it will have 3 input layers and n-kth word and n-k+1th word and document as the input and the output will have a nth word as the output
- So we have the context and the document on the input
- In the doc2vec we have both document embedding and word embedding
